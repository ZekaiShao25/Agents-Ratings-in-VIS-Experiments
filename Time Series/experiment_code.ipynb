{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please provide your OPENAI_KEY\n",
    "OPENAI_KEY = \"sk-<your-openai-key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "def run_local_vision_request(text, image_urls, temperature=0):\n",
    "    def encode_image(image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    api_key = OPENAI_KEY\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": text},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for image_path in image_urls:\n",
    "        # Getting the base64 string\n",
    "        base64_image = encode_image(image_path)\n",
    "        messages[0][\"content\"].append({\n",
    "            \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "        })\n",
    "\n",
    "    headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 2048,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def run_test(name, description, prompt, image_urls, logger, times=1):\n",
    "    response_list = []\n",
    "    while len(response_list) < times:\n",
    "        try:\n",
    "            response = run_local_vision_request(\n",
    "                text=prompt, \n",
    "                image_urls=image_urls,\n",
    "            )\n",
    "            matched_content = re.search(r'```json([\\s\\S]*?)```', response[\"choices\"][0][\"message\"][\"content\"])\n",
    "            if matched_content:\n",
    "                json_format_data = json.loads(matched_content.group(1))\n",
    "            else: \n",
    "                json_format_data = \"\"\n",
    "            logger.log(name, description, prompt, image_urls, response[\"choices\"][0][\"message\"][\"content\"], json_format_data)\n",
    "            response_list.append(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "    return response_list\n",
    "\n",
    "def get_result_by_description(data, name, description):\n",
    "    for result in data:\n",
    "        if name == result[\"name\"] and description == result[\"description\"]:\n",
    "            return result\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        \n",
    "    def log(self, name, description, prompt, image_urls, response, json_format_data):\n",
    "        json_data_to_add = {\"name\": name, \"description\": description, \"prompt\": prompt, \"image_urls\": image_urls, \"response\": response, \"json_format_data\": json_format_data}\n",
    "\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        data.append(json_data_to_add)\n",
    "\n",
    "        with open(self.file_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "logger = Logger(\"./time_series.json\")\n",
    "\n",
    "from paperqa import (\n",
    "    Docs,\n",
    ")\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "def image_to_gray(file_path, task_list, vis_list):\n",
    "    for task in task_list:\n",
    "        for vis in vis_list:\n",
    "            image_url = file_path + task + \"/\" + vis + \".png\"\n",
    "            image = Image.open(image_url)\n",
    "            gray_image = image.convert('L')\n",
    "            gray_image.save(file_path + task + \"/\" + vis + \"_gray\" + \".png\")\n",
    "\n",
    "def get_rag_database():\n",
    "    web_knowledge_line = Docs()\n",
    "    web_knowledge_heatmap = Docs()\n",
    "    web_knowledge_icicle = Docs()\n",
    "\n",
    "    # web_search(WEB_SEARCH.format(visualization=vis))\n",
    "    web_knowledge_line.add(\n",
    "        path=\"./experiment_material/web_knowledge_line.txt\", docname='web_knowledge_line')\n",
    "    web_knowledge_heatmap.add(\n",
    "        path=\"./experiment_material/web_knowledge_heatmap.txt\", docname='web_knowledge_heatmap')\n",
    "    web_knowledge_icicle.add(\n",
    "        path=\"./experiment_material/web_knowledge_icicle.txt\", docname='web_knowledge_icicle')\n",
    "\n",
    "    web_knowledge = {\"line\": web_knowledge_line,\n",
    "                \"heatmap\": web_knowledge_heatmap,\n",
    "                \"icicle\": web_knowledge_icicle,\n",
    "                }\n",
    "    return web_knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE = \"You are an average user. \"\n",
    "INTRODUCTION = \"These visualizations represent each day's sales. By looking at the visualizations, you know that here are 112 days: Each day follows the structure 'Day X-Week Y-Month Z', where 'X' denotes the day of the week (ranging from Day 1 to Day 7), 'Y' indicates the week of the month (ranging from Week 1 to Week 4), and 'Z' specifies the month of the year (January, February, March, April). {vis_introduction}\"\n",
    "MAXIMA = \"By looking at these three visualizations ({visualizations}), your goal is to identify the day(Day X-Week Y-Month Z) with the absolute highest sales through individual visualisations. Just determine which day has the maximum sale.\"\n",
    "MINIMA = \"By looking at these three visualizations ({visualizations}), your goal is to identify the day(Day X-Week Y-Month Z) with the absolute lowest sales through individual visualisations. Just determine which day has the minimum sale.\"\n",
    "COMPARISON = \"By looking at these three visualizations ({visualizations}), your goal is to discover which of the following weeks has the highest aggregated sales: {week_x} or {week_y} through different visualisations. Just determine which week of the two weeks has the greater total sales.\"\n",
    "TREND_DETECTION = \"By looking at these three visualizations ({visualizations}), your goal is to discover the week(Week Y-Month Z) with the smallest difference in sales between the first and last day through individual visualisations. Just determine which week has the smallest difference.\"\n",
    "DESCRIPTION = \"Please describe three visualizations({visualizations}) in details.\"\n",
    "STEP = \"You need to tell me the exact process of completing the task using the different visualisations and the problem you encountered, but not the answers.\"\n",
    "RATING = \"Here's how one person accomplishes a task: {steps} Based on the knowledge you have, assuming you are this person, you should answer two 5-point Likert scale questions for three different visualisations, ranging from strongly agree (5) to strongly disagree (1): (i) I feel confident about the given answer and (ii) I think this visualisation is easy to use for this task. And give the reason.\"\n",
    "WEB_SEARCH = \"Find some websites which introduce the {visualization}, and introduce the content about the {visualization}.\"\n",
    "JSON_FORMAT_DESCRIPTION = \"Please give an additional scoring result in json format at the end of your answe, like ```json{{'line': description, 'heatmap': description, 'icicle': description }}```.\"\n",
    "JSON_FORMAT_RATING = \"Please give an additional scoring result in json format at the end of your answe, like ```json{{'confidence': {{'line': value, 'heatmap': value, 'icicle': value}}, 'easy to use': {{'line': value, 'heatmap': value, 'icicle': value}} }}```.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list = [\"maxima\", \"minima\", \"comparison\", \"trend_detection\"]\n",
    "vis_list = [\"line\", \"heatmap\", \"icicle\", \"radar\", \"circular_heatmap\", \"sunburst\"]\n",
    "vis_introduction_dict = {\"line\": \"For line chart, the y-value of point indicates the the daily sale.\", \n",
    "                    \"heatmap\": \"For heatmap, the color shade of the cell indicates the daily sale.\", \n",
    "                    \"icicle\": \"For icicle plot, the size of the rectangle indicates the sale.\",\n",
    "                    \"radar\": \"For radar chart, the radial value indicates the sale. \",\n",
    "                    \"circular_heatmap\": \"For circular heatmap, the color shade of the cell indicates the daily sale.\",\n",
    "                    \"sunburst\": \"For sunburst visualisation, the angle covered by each sector represents the proportion of sale.\"}\n",
    "TASK_PROMPT = {\"maxima\": MAXIMA, \"minima\": MINIMA, \"comparison\": COMPARISON, \"trend_detection\": TREND_DETECTION}\n",
    "file_path = \"./experiment_material/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execution(task_list, vis_list, times):\n",
    "    name = \"time_series_experiment\"\n",
    "    for task in task_list:\n",
    "        image_urls = [file_path + task + \"/\" + vis + \".png\" for vis in vis_list]\n",
    "        for i in range(times):\n",
    "            # web_search(WEB_SEARCH.format(visualization=vis_list))\n",
    "            with open(\"./experiment_material/web_knowledge.txt\", \"r\") as f:\n",
    "                context = f.read()\n",
    "            visualizations = \",\".join(vis_list)\n",
    "            vis_introduction = \"\".join([vis_introduction_dict[vis] for vis in vis_list])\n",
    "            description = task + \"_description_\" + str(i)\n",
    "            prompt = ROLE + \\\n",
    "                    DESCRIPTION.format(visualizations=visualizations) + \\\n",
    "                    INTRODUCTION.format(vis_introduction=vis_introduction) + \\\n",
    "                    \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "            vis_description = run_test(\n",
    "                name, description, prompt, image_urls, logger, times=1)\n",
    "            \n",
    "            description = task + \"_steps_\" + str(i)\n",
    "            prompt = ROLE + \\\n",
    "                    TASK_PROMPT[task].format(visualizations=visualizations) + \\\n",
    "                    INTRODUCTION.format(vis_introduction=vis_introduction) + \\\n",
    "                    STEP + \\\n",
    "                    \"Description of three visualizations: \" + vis_description[0] + \\\n",
    "                    \"Context: \" + context + \\\n",
    "                    \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "            steps = run_test(name, description, prompt, image_urls, logger, times=1)\n",
    "\n",
    "            description = task + \"_rating_\" + str(i)\n",
    "            prompt = ROLE + \\\n",
    "                    TASK_PROMPT[task].format(visualizations=visualizations) + \\\n",
    "                    RATING.format(steps=steps) + \\\n",
    "                    JSON_FORMAT_RATING + \\\n",
    "                    \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "            rating = run_test(name, description, prompt, image_urls, logger, times=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task in task_list:\n",
    "    execution([task], vis_list, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Experiment (automatical knowledge injection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"time_series_extra_experiment\"\n",
    "task = \"comparison\"\n",
    "vis_list = [\"line\", \"heatmpa\", \"icicle\"]\n",
    "image_urls = [file_path + task + \"/\" + vis + \".png\" for vis in vis_list]\n",
    "\n",
    "# round1\n",
    "# web_search(WEB_SEARCH.format(visualization=vis_list))\n",
    "with open(\"./experiment_material/web_knowledge.txt\", \"r\") as f:\n",
    "    context = f.read()\n",
    "visualizations = \",\".join(vis_list)\n",
    "vis_introduction = \"\".join([vis_introduction_dict[vis] for vis in vis_list])\n",
    "description = task + \"_description_round1\"\n",
    "prompt = ROLE + \\\n",
    "        DESCRIPTION.format(visualizations=visualizations) + \\\n",
    "        INTRODUCTION.format(vis_introduction=vis_introduction) + \\\n",
    "        \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "vis_description = run_test(\n",
    "    name, description, prompt, image_urls, logger, times=1)\n",
    "\n",
    "description = task + \"_steps_round1\"\n",
    "prompt = ROLE + \\\n",
    "        TASK_PROMPT[task].format(visualizations=visualizations) + \\\n",
    "        INTRODUCTION.format(vis_introduction=vis_introduction) + \\\n",
    "        STEP + \\\n",
    "        \"Description of three visualizations: \" + vis_description[0] + \\\n",
    "        \"Context: \" + context + \\\n",
    "        \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "steps = run_test(name, description, prompt, image_urls, logger, times=1)\n",
    "\n",
    "# round2\n",
    "content = {\"line\": steps[0].split(\"1.\")[1].split(\"\\n\\n\")[0],\n",
    "            \"heatmap\": steps[0].split(\"2.\")[1].split(\"\\n\\n\")[0],\n",
    "            \"icicle\": steps[0].split(\"3.\")[1].split(\"\\n\\n\")[0],\n",
    "            }\n",
    "web_knowledge = get_rag_database()\n",
    "\n",
    "for vis in vis_list:\n",
    "    steps_str = content[vis]\n",
    "    split_text_double_newline = steps_str.split(\"\\n\\n\")\n",
    "    split_text_final = [chunk.split(\"\\n\") for chunk in split_text_double_newline]\n",
    "    for split_text1 in split_text_final:\n",
    "        for chunk in split_text1:\n",
    "            for i in range(0, 5):\n",
    "                description = task + \"_steps_round2_\" + str(i)\n",
    "                filter_context = web_knowledge[vis].query(query=chunk, max_sources=1).context\n",
    "                prompt = ROLE + \\\n",
    "                        TASK_PROMPT[task].format(visualizations=visualizations) + \\\n",
    "                        INTRODUCTION.format(vis_introduction=vis_introduction) + \\\n",
    "                        STEP + \\\n",
    "                        \"You can use the following context to assist your answer. Context: \\n\\n {\" + filter_context + \"}\\n\\n\" +  \\\n",
    "                        \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "                steps = run_test(name, description, prompt, image_urls, logger, times=1)\n",
    "\n",
    "                description = task + \"_rating_round2_\" + str(i)\n",
    "                prompt = ROLE + \\\n",
    "                        TASK_PROMPT[task].format(visualizations=visualizations) + \\\n",
    "                        RATING.format(steps=steps) + \\\n",
    "                        JSON_FORMAT_RATING + \\\n",
    "                        \"You can use the following context to assist your answer. Context: \\n\\n {\" + filter_context + \"}\\n\\n\" +  \\\n",
    "                        \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "                rating = run_test(name, description, prompt, image_urls, logger, times=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paperqa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

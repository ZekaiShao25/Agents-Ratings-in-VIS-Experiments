{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputation for Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please provide your OPENAI_KEY\n",
    "OPENAI_KEY = \"sk-<your-openai-key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "import requests\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "def run_local_vision_request(text, image_urls, temperature=0):\n",
    "    def encode_image(image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    api_key = OPENAI_KEY\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": text},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for image_path in image_urls:\n",
    "        # Getting the base64 string\n",
    "        base64_image = encode_image(image_path)\n",
    "        messages[0][\"content\"].append({\n",
    "            \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "        })\n",
    "\n",
    "    headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 2048,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def run_test2(name, description, prompt, image_urls, logger, times=1):\n",
    "    reason_list = []\n",
    "    score_list = []\n",
    "    while len(score_list) < times:\n",
    "        shuffled_list = image_urls.copy()\n",
    "        random.shuffle(shuffled_list)\n",
    "        index = [image_urls.index(x) for x in shuffled_list]\n",
    "        try:\n",
    "            response = run_local_vision_request(\n",
    "                text=prompt, \n",
    "                image_urls=shuffled_list,\n",
    "            )\n",
    "            matched_content = re.search(r'```json([\\s\\S]*?)```', response[\"choices\"][0][\"message\"][\"content\"])\n",
    "            response_list = json.loads(matched_content.group(1))\n",
    "            result = sorted(response_list, key=lambda x: index[response_list.index(x)])\n",
    "            reason_list.append(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "            score_list.append(sorted(response_list, key=lambda x: index[response_list.index(x)]))\n",
    "            logger.log(name, description, prompt, shuffled_list, response[\"choices\"][0][\"message\"][\"content\"], result)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return reason_list\n",
    "\n",
    "def run_test1(name, description, prompt, image_description, image_urls, logger, times=1):\n",
    "    reason_list = []\n",
    "    score_list = []\n",
    "    while len(score_list) < times:\n",
    "        shuffled_list = image_urls.copy()\n",
    "        random.shuffle(shuffled_list)\n",
    "        index = [image_urls.index(x) for x in shuffled_list]\n",
    "        description_shuffled = [''] * len(shuffled_list)\n",
    "        for i in range(len(shuffled_list)):\n",
    "            description_shuffled[index.index(i)] = image_description[i]\n",
    "        try:\n",
    "            prompt_format = prompt.format(first=description_shuffled[0], second=description_shuffled[1], third=description_shuffled[2], fourth=description_shuffled[3], fifth=description_shuffled[4])\n",
    "            response = run_local_vision_request(\n",
    "                text=prompt_format, \n",
    "                image_urls=shuffled_list,\n",
    "            )\n",
    "            matched_content = re.search(r'```json([\\s\\S]*?)```', response[\"choices\"][0][\"message\"][\"content\"])\n",
    "            response_list = json.loads(matched_content.group(1))\n",
    "            result = sorted(response_list, key=lambda x: index[response_list.index(x)])\n",
    "            reason_list.append(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "            score_list.append(sorted(response_list, key=lambda x: index[response_list.index(x)]))\n",
    "            logger.log(name, description, prompt_format, shuffled_list, response[\"choices\"][0][\"message\"][\"content\"], result)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return reason_list\n",
    "\n",
    "def run_request(system_message, user_message, client=OpenAI(), temperature=0):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-0125-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "class Logger1:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        \n",
    "    def log(self, name, description, prompt, image_urls, response, result):\n",
    "        json_data_to_add = {\"name\": name, \"description\": description, \"prompt\": prompt, \"image_urls\": image_urls, \"response\": response, \"result\": result}\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        data.append(json_data_to_add)\n",
    "        with open(self.file_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "\n",
    "class Logger2:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        \n",
    "    def log(self, name, description, prompt, image_urls, response, score):\n",
    "        json_data_to_add = {\"name\": name, \"description\": description, \"prompt\": prompt, \"image_urls\": image_urls, \"response\": response, \"score\": score}\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        data.append(json_data_to_add)\n",
    "        with open(self.file_path, 'w') as file:               \n",
    "            json.dump(data, file, indent=4)\n",
    "\n",
    "class Logger3:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        \n",
    "    def log_score(self, name, description, prompt, response, score):\n",
    "        json_data_to_add = {\"name\": name, \"description\": description, \"prompt\": prompt, \"response\": response, \"score\": score}\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        data.append(json_data_to_add)\n",
    "        with open(self.file_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "    \n",
    "    def log(self, name, description, prompt, response):\n",
    "        json_data_to_add = {\"name\": name, \"description\": description, \"prompt\": prompt, \"response\": response}\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        data.append(json_data_to_add)\n",
    "        with open(self.file_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "logger1 = Logger1(\"./uncertainty.json\")\n",
    "logger2 = Logger2(\"./uncertainty.json\")\n",
    "logger3 = Logger3(\"./uncertainty.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE = \"You are an average user. \"\n",
    "MEAN_TASK = '''The graphs show the relationship between two variables X and Y. The points belong to two groups Cyan and Orange.   \n",
    "However, the original dataset has certain missing values in either the X or Y for every variable. We use a statistical method called imputation to estimate these points. The point represents the most likely (average) estimate of the missing data point derived from the imputation method. However, as imputation cannot precisely estimate values for the missing data points, we also get some uncertainty from our imputation method.\n",
    "There are five different uncertainty representations, each for a graph provided.\n",
    "In the first graph {first}.\n",
    "In the second graph {second}.\n",
    "In the third graph {third}.\n",
    "In the fourth graph {fourth}.\n",
    "In the fifth graph {fifth}.\n",
    "With the introduction above, you need to understand the visualizations and finish the tasks based on the visualization.\n",
    "PRIOR PRINCIPLE: When dealing with the task, please simulate the role of an average human participant who is reading the visualizations and answering the questions without any computational tools. So you need to choose the way of dealing with the task based on a human perspective, and NOTE that humans are subject to cognitive and perceptual factors.\n",
    "###Tasks###\n",
    "For each uncertainty representation, complete the following task:\n",
    "{task}\n",
    "You need to tell me the exact process of completing the task using the visualizations and the difficulties you may encounter, and DO NOT give your final answer of the task. \n",
    "'''\n",
    "\n",
    "TREND_TASK = '''The graphs show the relationship between two variables X and Y. The points belong to two groups Cyan and Orange.   \n",
    "However, the original dataset has certain missing values in either the X or Y for every variable. We use a statistical method called imputation to estimate these points. The point represents the most likely (average) estimate of the missing data point derived from the imputation method. However, as imputation cannot precisely estimate values for the missing data points, we also get some uncertainty from our imputation method.\n",
    "There are five different uncertainty representations, each for a graph provided.\n",
    "In the first graph {first}.\n",
    "In the second graph {second}.\n",
    "In the third graph {third}.\n",
    "In the fourth graph {fourth}.\n",
    "In the fifth graph {fifth}.\n",
    "With the introduction above, you need to understand the visualizations and finish the tasks based on the visualization.\n",
    "PRIOR PRINCIPLE: When dealing with the task, please simulate the role of an average human participant who is reading the visualizations and answering the questions without any computational tools. So you need to choose the way of dealing with the task based on a human perspective, and NOTE that humans are subject to cognitive and perceptual factors.\n",
    "###Tasks###\n",
    "For each uncertainty representation, complete the following task:\n",
    "{task}\n",
    "You need to tell me the exact process of completing the task using the visualizations and the difficulties you may encounter, and DO NOT give your final answer of the task. \n",
    "'''\n",
    "\n",
    "JSON_FORMAT = '''Please give an additional result in json format at the end of your answe, like \n",
    "```json[\n",
    "    {{\"steps\": steps, \"difficulties\": difficulties (also provide your reason inside this value)}},\n",
    "    {{\"steps\": steps, \"difficulties\": difficulties (also provide your reason inside this value)}},\n",
    "    {{\"steps\": steps, \"difficulties\": difficulties (also provide your reason inside this value)}},\n",
    "    {{\"steps\": steps, \"difficulties\": difficulties (also provide your reason inside this value)}},\n",
    "    {{\"steps\": steps, \"difficulties\": difficulties (also provide your reason inside this value)}},\n",
    "]```.\n",
    "'''\n",
    "RATING = \"Based on the background, someone gives the following analysis: {steps}. From the human perspective you are simulating, for each of the representations, rate your confidence in your answer on a scale of 1 to 5 with 5 representing the highest confidence. Further give an estimated number of how many will give a confidence level of no less than 3 per 100 persons. As an average human participant, DO NOT state individual variance on this task, and you MUST give an specific answer. Note that the confidence level you give should be highly related with your estimated number of how many will give a confidence level of no less than 3 per 100 persons.\"\n",
    "RATING_JSON_FORMAT = '''Please give an additional result in json format at the end of your answe, like \n",
    "```json[ score1, score2, score3, score4, score5]```.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "# f\"{file_path}{type}/{task}/proportion{proportion}/error{error}/{number}.png\"\n",
    "tasks = {\"mean\": MEAN_TASK, \"trend\": TREND_TASK}\n",
    "task_description = {\"mean\": \"Based on the understanding of how missing data is imputed, estimate the average value of X of the whole dataset(including both cyan and orange group, and both real and imputed data).\",\n",
    "                    \"trend\": \"Based on the understanding of how missing data is imputed, identify the trend line which best represents the relationship between x and y(including both cyan and orange group, and both real and imputed data).\"}\n",
    "file_path = \"./experiment_material/experiment_preparation/images/\"\n",
    "type_list = [\"none\", \"mean\", \"ci\", \"density\", \"gradient\"]\n",
    "proportion_list = [\"30\", \"50\"]\n",
    "error_list = [\"15\", \"20\"]\n",
    "mean_number_list = [\"graph-x-001\", \"graph-y-002\"]\n",
    "trend_number_list = [\"graph-xy-001\", \"graph-xy-002\"]\n",
    "image_description = [\n",
    "    \" (none), data points with missing values are not shown as they cannot be accurately plotted on the chart\",\n",
    "    \" (mean), the missing points are estimated, and the mean of these estiamtes are represented as hollow points\",\n",
    "    \" (ci), we represent this uncertainty using the bars which represent the 95% confidence interval.This interval tells you the uncertainty associated with the imputed value\",\n",
    "    \" (density), we represent this uncertainty using the probability density plots\",\n",
    "    \" (gradient), we represent this uncertainty using the gradient plots showing 95% confidence intervals.This interval tells you the uncertainty associated with the imputed value\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"uncertainty_experiment\"\n",
    "task = \"mean\"\n",
    "for proportion in proportion_list:\n",
    "    for error in error_list:\n",
    "        for number in mean_number_list:\n",
    "            description = f\"{task}_proportion{proportion}_error{error}_{number}_step1\"\n",
    "            image_urls = [f\"{file_path}{_type}/{task}/proportion{proportion}/error{error}/{number}.png\" for _type in type_list]\n",
    "            prompt = ROLE + \\\n",
    "                    tasks[task] + \\\n",
    "                    JSON_FORMAT + \" \"\\\n",
    "                    \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "            #  get the exact process of completing the task\n",
    "            responses = run_test1(\n",
    "                name=name,\n",
    "                description=description,\n",
    "                prompt=prompt,\n",
    "                image_urls=image_urls,\n",
    "                image_description=image_description,\n",
    "                logger=logger1,\n",
    "                times=5)\n",
    "            \n",
    "            for response in responses:\n",
    "                prompt = ROLE + \\\n",
    "                        tasks[task] + \\\n",
    "                        RATING.format(steps=response) + \\\n",
    "                        RATING_JSON_FORMAT + \\\n",
    "                        \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "                description = f\"{task}_proportion{proportion}_error{error}_{number}_step2\"\n",
    "                # get the rating result\n",
    "                run_test2(\n",
    "                    name=name,\n",
    "                    description=description,\n",
    "                    prompt=prompt,\n",
    "                    image_urls=image_urls,\n",
    "                    logger=logger2,\n",
    "                    times=1)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"uncertainty_experiment\"\n",
    "for proportion in proportion_list:\n",
    "    for error in error_list:\n",
    "        for number in trend_number_list:\n",
    "            description = f\"trend_proportion{proportion}_error{error}_{number}_step1\"\n",
    "            image_urls = [f\"{file_path}{_type}/trend/proportion{proportion}/error{error}/{number}.png\" for _type in type_list]\n",
    "            prompt = ROLE + \\\n",
    "                    TREND_TASK + \\\n",
    "                    JSON_FORMAT + \" \"\\\n",
    "                    \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "            #  get the exact process of completing the task\n",
    "            responses = run_test1(\n",
    "                name=name,\n",
    "                description=description,\n",
    "                prompt=prompt,\n",
    "                image_urls=image_urls,\n",
    "                image_description=image_description,\n",
    "                logger=logger1,\n",
    "                times=5)\n",
    "            \n",
    "            for response in responses:\n",
    "                prompt = ROLE + \\\n",
    "                        TREND_TASK + \\\n",
    "                        RATING.format(steps=response) + \\\n",
    "                        RATING_JSON_FORMAT + \\\n",
    "                        \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "                description = f\"trend_proportion{proportion}_error{error}_{number}_step2\"\n",
    "                # get the rating result\n",
    "                run_test2(\n",
    "                    name=name,\n",
    "                    description=description,\n",
    "                    prompt=prompt,\n",
    "                    image_urls=image_urls,\n",
    "                    logger=logger2,\n",
    "                    times=1)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE = \"You are an expert in visualization.\"\n",
    "INTRODUCTION = \"There are five kinds of uncertainty representations: baseline(not showing imputed data), mean(only showing the mean of point estimation of imputed data using hollow points), CI(represent the uncertainty using the bars which represent the 95% confidence interval), density(represent the uncertainty using the probability density plots), gradient(represent the uncertainty using the gradient plots showing 95% confidence intervals).\"\n",
    "MEAN_DIFFICULTY = \"What difficulties will human observer encounter when faced with uncertainty representations for imputed data on a 2D scatter plot and required to estimate the mean of the whole dataset, considering human are subject to cognitive and perceptual factors.\"\n",
    "TREND_DIFFICULTY = \"What difficulties will human observer encounter when faced with uncertainty representations for imputed data on a 2D scatter plot and required to identify the trend line which best represents the relationship between x and y, considering human are subject to cognitive and perceptual factors.\"\n",
    "RATING = \"From the human perspective you are simulating, for each of the representations, rate your confidence in your answer on a scale of 1 to 5 with 5 representing the highest confidence. Please give an additional result in json format at the end of your answe, like ```json[ confidence_level1, confidence_level2, confidence_level3, confidence_level4, confidence_level5]```.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Execution\n",
    "Give ratings without images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "for i in range(10):\n",
    "    response_general_knowledge = run_request(\n",
    "        user_message=MEAN_DIFFICULTY,\n",
    "        system_message=ROLE\n",
    "    )\n",
    "    DIFFICULTY = response_general_knowledge.choices[0].message.content\n",
    "\n",
    "    response_application = run_request(\n",
    "        user_message=DIFFICULTY + INTRODUCTION + RATING,\n",
    "        system_message=ROLE\n",
    "    )\n",
    "    rating = response_application.choices[0].message.content\n",
    "    matched_content = re.search(r'```json([\\s\\S]*?)```', rating)\n",
    "    score = json.loads(matched_content.group(1))\n",
    "    score_list.append(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trend task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "for i in range(10):\n",
    "    response_general_knowledge = run_request(\n",
    "        user_message=TREND_DIFFICULTY,\n",
    "        system_message=ROLE\n",
    "    )\n",
    "    DIFFICULTY = response_general_knowledge.choices[0].message.content\n",
    "\n",
    "    response_application = run_request(\n",
    "        user_message=DIFFICULTY + INTRODUCTION + RATING,\n",
    "        system_message=ROLE\n",
    "    )\n",
    "    rating = response_application.choices[0].message.content\n",
    "    matched_content = re.search(r'```json([\\s\\S]*?)```', rating)\n",
    "    score = json.loads(matched_content.group(1))\n",
    "    score_list.append(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paperqa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

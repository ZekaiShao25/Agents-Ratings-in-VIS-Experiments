{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literacy in Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import requests\n",
    "import base64\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "def run_local_vision_request(text, image_urls, temperature=0):\n",
    "    # Function to encode the image\n",
    "    def encode_image(image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    api_key = \"OPENAI_KEY\"\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": text},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for image_path in image_urls:\n",
    "        # Getting the base64 string\n",
    "        base64_image = encode_image(image_path)\n",
    "        messages[0][\"content\"].append({\n",
    "            \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "        })\n",
    "\n",
    "    headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 2048,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def run_test(name, description, prompt, image_urls, logger, times=1):\n",
    "    response_list = []\n",
    "    while len(response_list) < times:\n",
    "        try:\n",
    "            response = run_local_vision_request(\n",
    "                text=prompt, \n",
    "                image_urls=image_urls,\n",
    "            )\n",
    "            matched_content = re.search(r'```json([\\s\\S]*?)```', response[\"choices\"][0][\"message\"][\"content\"])\n",
    "            answer = json.loads(matched_content.group(1))\n",
    "            logger.log(name, description, prompt, image_urls, response[\"choices\"][0][\"message\"][\"content\"], answer)\n",
    "            response_list.append(response)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return response_list\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        \n",
    "    def log(self, name, description, prompt, image_urls, response, answer):\n",
    "        json_data_to_add = {\"name\": name, \"description\": description, \"prompt\": prompt, \"image_urls\": image_urls, \"response\": response, \"answer\": answer}\n",
    "\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        data.append(json_data_to_add)\n",
    "\n",
    "        with open(self.file_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "            \n",
    "logger = Logger(\"./calvi.json\")\n",
    "\n",
    "\n",
    "def resize_image(image_path, output_path):\n",
    "    with open(image_path, 'rb') as file:\n",
    "        signature = file.read(8)\n",
    "    if signature == b'\\x89PNG\\r\\n\\x1a\\n':\n",
    "        original_image = Image.open(image_path)\n",
    "        width, height = original_image.size\n",
    "        new_width = width // 2\n",
    "        new_height = height // 2\n",
    "        \n",
    "        reduced_image = original_image.resize((new_width, new_height), Image.Resampling.LANCZOS)\n",
    "\n",
    "        resized_image = reduced_image.resize((width, height), Image.BILINEAR)\n",
    "        \n",
    "        resized_image.save(output_path)\n",
    "\n",
    "def mask_image():\n",
    "    directory_path = \"./calvi/question/\"\n",
    "    target_path = \"./calvi/visualization/\"\n",
    "    file_names = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "    with open(\"./calvi/items_data_revised.json\", \"r\") as f:\n",
    "        answers = json.load(f)\n",
    "        \n",
    "    for file in file_names[0:12] + file_names[13:]:\n",
    "        if int(re.search(r\"-(\\d+)\", file).group(1)) < 48:\n",
    "            answer = answers[re.search(r\"-(\\d+)\", file).group(1)]\n",
    "            if len(answer[\"Option\"]) == 4:\n",
    "                cover_height_down = 540\n",
    "            else:\n",
    "                cover_height_down = 340\n",
    "            img_path = directory_path + file\n",
    "            img = Image.open(img_path)\n",
    "\n",
    "            width, height = img.size\n",
    "\n",
    "            cover_height_up = 100\n",
    "            cover_height_down = 520\n",
    "\n",
    "            draw = ImageDraw.Draw(img)\n",
    "\n",
    "            draw.rectangle([0, 0, width, cover_height_up], fill=\"white\")  # 上方\n",
    "            draw.rectangle([0, height-cover_height_down, width, height], fill=\"white\")  # 下方\n",
    "\n",
    "            img.save(target_path + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE = \"You are an average user. \"\n",
    "TASK = \"Please answer the question in the image and give your reason for the answer.\"\n",
    "RATING_JSON_FORMAT = '''Please give an additional result in json format at the end of your answer, like \n",
    "```json{\"answer\": answer, \"description\": description}```.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"./calvi/visualization/\"\n",
    "with open(\"./calvi/items_data_revised.json\", \"r\") as f:\n",
    "    answers = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"experiment1\"\n",
    "file_names = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "for file in file_names:\n",
    "    description = \"answer_question_\" + file\n",
    "    image_urls = [directory_path + file]\n",
    "    index = re.search(r\"-(\\d+)\", file).group(1)\n",
    "    if int(index) < 48:\n",
    "        answer = answers[index]\n",
    "        QUESTION_OPTIONS = answer[\"Question\"] + \" Your answer should be one of \" + str(answer[\"Option\"]) + \". \"\n",
    "        prompt = ROLE + \\\n",
    "            QUESTION_OPTIONS + \\\n",
    "            TASK + \\\n",
    "            RATING_JSON_FORMAT + \\\n",
    "            \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "        run_test(name, description, prompt, image_urls, logger, times=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE = \"You are a visualization expert. \"\n",
    "TASK = \"Please rate the item on a scale of 1 (not relevant) to 4 (highly relevant) based on the image and give your reason. The relevance meaning that differences in ability (i.e., the ability to read, interpret, and reason about erroneous or potentially misleading visualizations) should lead to differences in measurement outcomes (i.e., correctness). High relevance indicates that this vis and task contain high-related misleading elements. Also give your answer to the question.\"\n",
    "RATING_JSON_FORMAT = '''Please give an additional result in json format at the end of your answe, like \n",
    "```json{\"score\": score, \"reason\": reason, \"answer\": answer}```.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"./calvi/visualization/\"\n",
    "with open(\"./calvi/items_data_revised.json\", \"r\") as f:\n",
    "    answers = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"experiment2\"\n",
    "\n",
    "file_names = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "for file in file_names:\n",
    "    description = \"expert_\" + file\n",
    "    image_urls = [directory_path + file]\n",
    "    index = re.search(r\"-(\\d+)\", file).group(1)\n",
    "    if int(index) < 48 or int(index) > 71:\n",
    "        answer = answers[index]\n",
    "        QUESTION_OPTIONS = answer[\"Question\"] + \" Your answer should be one of \" + str(answer[\"Option\"]) + \". \"\n",
    "        prompt = ROLE + \\\n",
    "            QUESTION_OPTIONS + \\\n",
    "            TASK + \\\n",
    "            RATING_JSON_FORMAT + \\\n",
    "            \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "        run_test(name, description, prompt, image_urls, logger, times=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correctness judgment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_by_description(data, name, description):\n",
    "    results = []\n",
    "    for result in data:\n",
    "        if name == result[\"name\"] and description == result[\"description\"]:\n",
    "            results.append(result)\n",
    "    return results\n",
    "\n",
    "def judge_correctness():\n",
    "    with open(\"./calvi/items_data_revised.json\", \"r\") as f:\n",
    "        answers = json.load(f)\n",
    "    with open(\"./calvi.json\", \"r\") as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    directory_path = \"./calvi/visualization/\"\n",
    "\n",
    "    # 获取目录下的所有文件名\n",
    "    file_names = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "    for file in file_names:\n",
    "        name, ext = os.path.splitext(file)\n",
    "        if ext == '.png' and (int(re.search(r\"-(\\d+)\", file).group(1)) < 48 or int(re.search(r\"-(\\d+)\", file).group(1)) > 64):\n",
    "            result_list = get_result_by_description(data=results, name=\"experiment2\", description=\"expert_visualization_\" + file)\n",
    "            \n",
    "            for result in result_list:\n",
    "                answer = answers[re.search(r\"-(\\d+)\", file).group(1)]\n",
    "                if type(answer[\"Best Answer\"]) == list:\n",
    "                    for _answer in answer[\"Best Answer\"]:\n",
    "                        if str(result[\"answer\"][\"answer\"]) == str(_answer):\n",
    "                            result[\"Best Answer\"] = True\n",
    "                            break\n",
    "                        else:\n",
    "                            result[\"Best Answer\"] = False\n",
    "                else:\n",
    "                    if str(result[\"answer\"][\"answer\"]) == str(answer[\"Best Answer\"]):\n",
    "                        result[\"Best Answer\"] = True\n",
    "                    else:\n",
    "                        result[\"Best Answer\"] = False\n",
    "                if \"Wrong-Due-To-Misleader Answer\" in answer:\n",
    "                    if  type(answer[\"Wrong-Due-To-Misleader Answer\"]) == list:\n",
    "                        for _answer in answer[\"Wrong-Due-To-Misleader Answer\"]:\n",
    "                            if str(result[\"answer\"][\"answer\"]) == str(_answer):\n",
    "                                result[\"Wrong-Due-To-Misleader Answer\"] = True\n",
    "                                break\n",
    "                            else:\n",
    "                                result[\"Wrong-Due-To-Misleader Answer\"] = False\n",
    "                    else:\n",
    "                        if str(result[\"answer\"][\"answer\"]) == str(answer[\"Wrong-Due-To-Misleader Answer\"]):\n",
    "                            result[\"Wrong-Due-To-Misleader Answer\"] = True\n",
    "                        else:\n",
    "                            result[\"Wrong-Due-To-Misleader Answer\"] = False\n",
    "                \n",
    "\n",
    "    with open(\"./calvi.json\", 'w') as file:\n",
    "        json.dump(results, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization with Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"extra_experiment\"\n",
    "# image with question and options\n",
    "directory_path = \"./calvi/question/\"\n",
    "file_names = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "for file in file_names:\n",
    "    description = \"visualization_with_text_\" + file\n",
    "    image_urls = [directory_path + file]\n",
    "    index = re.search(r\"-(\\d+)\", file).group(1)\n",
    "    if int(index) < 48:\n",
    "        prompt = ROLE + \\\n",
    "            TASK + \\\n",
    "            RATING_JSON_FORMAT + \\\n",
    "            \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "        run_test(name, description, prompt, image_urls, logger, times=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vague Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"extra_experiment\"\n",
    "# vague image\n",
    "directory_path = \"./calvi/visualization_vague/\"\n",
    "file_names = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "for file in file_names:\n",
    "    description = \"vague_\" + file\n",
    "    image_urls = [directory_path + file]\n",
    "    index = re.search(r\"-(\\d+)\", file).group(1)\n",
    "    if int(index) < 48:\n",
    "        answer = answers[index]\n",
    "        QUESTION_OPTIONS = answer[\"Question\"] + \" Your answer should be one of \" + str(answer[\"Option\"]) + \". \"\n",
    "        prompt = ROLE + \\\n",
    "            QUESTION_OPTIONS + \\\n",
    "            TASK + \\\n",
    "            RATING_JSON_FORMAT + \\\n",
    "            \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "        run_test(name, description, prompt, image_urls, logger, times=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paperqa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

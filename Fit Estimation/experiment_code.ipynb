{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please provide your OPENAI_KEY\n",
    "OPENAI_KEY = \"sk-<your-openai-key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "def run_local_vision_request(text, image_urls, temperature=0):\n",
    "    def encode_image(image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    api_key = OPENAI_KEY\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": text},\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for image_path in image_urls:\n",
    "        # Getting the base64 string\n",
    "        base64_image = encode_image(image_path)\n",
    "        messages[0][\"content\"].append({\n",
    "            \"image_url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "        })\n",
    "\n",
    "    headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"messages\": messages,\n",
    "        \"max_tokens\": 2048,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def run_test(name, description, prompt, image_urls, logger, times=1):\n",
    "    reason_list = []\n",
    "    score_list = []\n",
    "    while len(score_list) < times:\n",
    "        shuffled_list = image_urls.copy()\n",
    "        random.shuffle(shuffled_list)\n",
    "        try:\n",
    "            response = run_local_vision_request(\n",
    "                text=prompt, \n",
    "                image_urls=shuffled_list,\n",
    "            )\n",
    "            matched_content = re.search(r'```json([\\s\\S]*?)```', response[\"choices\"][0][\"message\"][\"content\"])\n",
    "            shuffled_score = json.loads(matched_content.group(1))\n",
    "            score = shuffled_score.copy()\n",
    "            for i in range(len(score)):\n",
    "                score[i] = shuffled_score[shuffled_list.index(image_urls[i])]\n",
    "            reason_list.append(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "            score_list.append(score)\n",
    "            logger.log(name, description, prompt, shuffled_list, response[\"choices\"][0][\"message\"][\"content\"], score)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return reason_list\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        \n",
    "    def log(self, name, description, prompt, image_urls, response, score):\n",
    "        json_data_to_add = {\"name\": name, \"description\": description, \"prompt\": prompt, \"image_urls\": image_urls, \"response\": response, \"score\": score}\n",
    "        with open(self.file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        data.append(json_data_to_add)\n",
    "        with open(self.file_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "\n",
    "logger = Logger(\"./fit_estimation.json\")\n",
    "\n",
    "\n",
    "def revise(file_path, name, description, image_urls):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    for result in data:\n",
    "        if result[\"name\"] == name and result[\"description\"] == description:\n",
    "            matched_content = re.search(r'```json([\\s\\S]*?)```', result[\"response\"])\n",
    "            shuffle_score = json.loads(matched_content.group(1))\n",
    "            score = shuffle_score.copy()\n",
    "            for i in range(len(score)):\n",
    "                score[i] = shuffle_score[result['image_urls'].index(image_urls[i])]\n",
    "            result['score'] = score\n",
    "\n",
    "    with open(\"./fit_estimation.json\", 'w') as file:\n",
    "        json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE = \"You are an average user. \"\n",
    "TASK = 'Here are {number} scatterplots. You are instructed to estimate how well the data points fitted to the shown line. Your score ranges from 0 (very low fit) to 100 (very high fit), a perfect fit would be to have all data points on the line. Please list the scores and the reason in the order of the images. '\n",
    "JSON_FORMAT = \"Please give an additional scoring result in json format at the end of your answe, like ```json[score1, score2, ...]```. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./experiment_material/stimuli_exp1+exp2/\"\n",
    "sd_list = [\"exp1_sd05\", \"exp1_sd10\",\"exp1_sd15\",\"exp1_sd20\",\"exp1_sd25\",]\n",
    "index_list = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Execution(parallel experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"fit_estimation_experiment1\"\n",
    "for i in index_list:\n",
    "    description = \"parallel_experiment_\" + i\n",
    "    image_urls = [file_path + sd + \"_\" + i + \".png\" for sd in sd_list]\n",
    "    prompt = ROLE + \\\n",
    "        TASK.format(number=len(image_urls)) + \\\n",
    "        JSON_FORMAT + \\\n",
    "        \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "    run_test(\n",
    "        name=name,\n",
    "        description=description,\n",
    "        prompt=prompt,\n",
    "        image_urls=image_urls,\n",
    "        logger=logger,\n",
    "        times=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE = \"You are an average user. \"\n",
    "TASK = 'Here are {number} scatterplots. You are instructed to estimate how well the data points fitted to the shown line. Your score ranges from 0 (very low fit) to 100 (very high fit), a perfect fit would be to have all data points on the line. Please list the scores and the reason in the order of the images. '\n",
    "JSON_FORMAT = \"Please give an additional scoring result in json format at the end of your answe, like ```json[score1, score2, ...]```. \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./experiment_material/stimuli_exp1+exp2/\"\n",
    "sd_list = [\"02\", \"04\", \"06\", \"08\", \"10\", \"12\"]\n",
    "type_list = [\"neutral\", \"light_down\", \"light_up\", \"middle_down\", \"middle_up\", \"strong_down\", \"strong_up\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Execution(Same SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"fit_estimation_experiment2\"\n",
    "for sd in sd_list:\n",
    "    description = \"parallel_experiment_same_sd_\" + sd\n",
    "    image_urls = [file_path + \"exp2_sd\" + sd + \"_\" + t + \".png\" for t in type_list]\n",
    "    prompt = ROLE + \\\n",
    "        TASK.format(number=len(image_urls)) + \\\n",
    "        JSON_FORMAT + \\\n",
    "        \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "    run_test(\n",
    "        name=name,\n",
    "        description=description,\n",
    "        prompt=prompt,\n",
    "        image_urls=image_urls,\n",
    "        logger=logger,\n",
    "        times=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare SD with Decentering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"extra_experience\"\n",
    "description = \"compare_sd02_strong_sd04_neutral\"\n",
    "image_urls = ['./fit/stimuli_exp1+exp2/exp2_sd02_strong_up.png',\n",
    "              './fit/stimuli_exp1+exp2/exp2_sd02_strong_down.png',\n",
    "              './fit/stimuli_exp1+exp2/exp2_sd04_neutral.png',]\n",
    "prompt = ROLE + \\\n",
    "    TASK.format(number=len(image_urls)) + \\\n",
    "    JSON_FORMAT + \\\n",
    "    \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "run_test(\n",
    "    name=name,\n",
    "    description=description,\n",
    "    prompt=prompt,\n",
    "    image_urls=image_urls,\n",
    "    logger=logger,\n",
    "    times=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"extra_experience\"\n",
    "description = \"compare_sd04_middle_sd06_neutral\"\n",
    "image_urls = ['./fit/stimuli_exp1+exp2/exp2_sd04_middle_up.png',\n",
    "              './fit/stimuli_exp1+exp2/exp2_sd04_middle_down.png',\n",
    "              './fit/stimuli_exp1+exp2/exp2_sd06_neutral.png',]\n",
    "prompt = ROLE + \\\n",
    "    TASK.format(number=len(image_urls)) + \\\n",
    "    JSON_FORMAT + \\\n",
    "    \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "run_test(\n",
    "    name=name,\n",
    "    description=description,\n",
    "    prompt=prompt,\n",
    "    image_urls=image_urls,\n",
    "    logger=logger,\n",
    "    times=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"extra_experience\"\n",
    "description = \"compare_sd02_sd12\"\n",
    "up = ['./fit/stimuli_exp1+exp2/exp2_sd02_light_up.png',\n",
    "      './fit/stimuli_exp1+exp2/exp2_sd02_middle_up.png',\n",
    "      './fit/stimuli_exp1+exp2/exp2_sd02_strong_up.png',\n",
    "      './fit/stimuli_exp1+exp2/exp2_sd12_light_up.png',\n",
    "      './fit/stimuli_exp1+exp2/exp2_sd12_middle_up.png',\n",
    "      './fit/stimuli_exp1+exp2/exp2_sd12_strong_up.png', \n",
    "      ]\n",
    "down = ['./fit/stimuli_exp1+exp2/exp2_sd02_light_down.png',\n",
    "      './fit/stimuli_exp1+exp2/exp2_sd02_middle_down.png',\n",
    "      './fit/stimuli_exp1+exp2/exp2_sd02_strong_down.png',\n",
    "      './fit/stimuli_exp1+exp2/exp2_sd12_light_down.png',\n",
    "      './fit/stimuli_exp1+exp2/exp2_sd12_middle_down.png',\n",
    "      './fit/stimuli_exp1+exp2/exp2_sd12_strong_down.png', \n",
    "      ]\n",
    "netural = ['./fit/stimuli_exp1+exp2/exp2_sd02_neutral.png',\n",
    "           './fit/stimuli_exp1+exp2/exp2_sd12_neutral.png',]\n",
    "\n",
    "for i in range(10):\n",
    "    description = \"compare_sd02_sd12\" + \"_parallel_experiment_\" + str(i + 1)\n",
    "    image_urls = netural[0:1] + [random.choice([u, d]) for u, d in zip(up[0:3], down[0:3])] + netural[1:2] + [random.choice([u, d]) for u, d in zip(up[3:6], down[3:6])]\n",
    "    prompt = ROLE + \\\n",
    "    TASK.format(number=len(image_urls)) + \\\n",
    "    JSON_FORMAT + \\\n",
    "    \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "    run_test(\n",
    "        name=name,\n",
    "        description=description,\n",
    "        prompt=prompt,\n",
    "        image_urls=image_urls,\n",
    "        logger=logger,\n",
    "        times=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential Senario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"scenario2_6image\"\n",
    "image_urls = [\n",
    "    \"./fit/images_for_scenario2/sd0.2_decenter0.png\",\n",
    "    \"./fit/images_for_scenario2/sd0.2_decenter0.99_downwards.png\",\n",
    "    \"./fit/images_for_scenario2/sd0.2_decenter0.99_upwards.png\",\n",
    "    \"./fit/images_for_scenario2/sd0.4_decenter0.png\",\n",
    "    \"./fit/images_for_scenario2/sd0.4_decenter0.99_downwards.png\",\n",
    "    \"./fit/images_for_scenario2/sd0.4_decenter0.99_upwards.png\",\n",
    "]\n",
    "\n",
    "prompt = ROLE + \\\n",
    "    TASK.format(number=len(image_urls)) + \\\n",
    "    JSON_FORMAT + \\\n",
    "    \"DON'T say sorry or you cannot. YOU CAN.\"\n",
    "run_test(\n",
    "    name=name,\n",
    "    description=description,\n",
    "    prompt=prompt,\n",
    "    image_urls=image_urls,\n",
    "    logger=logger,\n",
    "    times=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paperqa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
